\subsection*{Tipos de ecuaciones lineales}
\label{sec:0_tipos_de_ecuaciones_lineales}
\setcounter{equation}{0}
\setcounter{definition}{1}

Sean $A, B, C, m, x$ números reales y $x, y$ variables. Las ecuaciones lineales son aquellas que pueden expresarse de las siguientes formas:

\begin{enumerate}
\item Pendiente ordenada al origen de la recta:
\begin{align*}
    y = mx + b
\end{align*}
\item Forma normal de la recta:
\begin{align*}
    Ax + By + C = 0
\end{align*}
\item Forma general de la recta:
\begin{align*}
    Ax + By = C
\end{align*}
\item Forma punto pendiente de la recta:
\begin{align*}
    (y - y_1) = m(x - x_1)
\end{align*}
\item Forma simétrica de la recta:
\begin{align*}
    \frac{x}{a} + \frac{y}{b} = 1
\end{align*}
\end{enumerate}

\begin{note}
[
    Los resultados de investigación suelen entregarse en la forma general de la recta.
]
\end{note}

El álgebra lineal pretende conocer la información de los sistemas de ecuaciones lineales. Le interesa si un problema tiene una, muchas o ninguna solución.

\subsection*{Métodos de solución de ecuaciones lineales}
\label{sec:0_metodos_de_solucion_de_ecuaciones_lineales}

\begin{enumerate}
    \item Método de sustitución.
    \item Sumas y restas ($+/-$).
    \item Método de igualación.
    \item Método de Cramer.
    \item Método de Gauss-Jordan.
\end{enumerate}

\subsection*{Ejercicios}
\label{sec:0_ejercicios}

Resuelve los siguientes sistemas de ecuaciones lineales para $x$ y $y$:

\begin{enumerate}
    \item $x-y = 7 \\ x+y = 5$
    \item $x-y = 7 \\ 2x-2y = 14$
    \item $x-y = 7 \\ 2x-2y = 13$
\end{enumerate}

\subsection*{Notas sobre cada ejercicio}
\label{sec:0_notas_sobre_cada_ejercicio}

\begin{enumerate}
    \item Es un sistema \textbf{no singular}. \\ Tiene solución única. \\ Es resultado de la igualdad $n = n, \quad n \in \mathbb{R}$.
    \item Es un sistema \textbf{singular}. \\ Tiene infinitas soluciones. \\ Es resultado de la igualdad $0=0$. \\ La solución $\in (-\infty, \infty)$.
    \item Es un sistema \textbf{singular}. \\ No tiene solución. \\ Es resultado de la igualdad $0 = n, \quad n \in \mathbb{R}, \quad n \neq 0$. \\ Es decir, el resultado es una inconsistencia.
\end{enumerate}

\subsection*{Operadores gaussianos}
\label{sec:0_operadores_gaussianos}

\begin{enumerate}
    \item \textbf{Operador de suma de filas} (Suma y resta): \\ $R_{i} \leftarrow R_{i} + R_{j}$.
    \item \textbf{Operador de multiplicación por un escalar:} \\ $R_{i} \leftarrow \alpha R_{i}$.
    \item \textbf{Suma y resta + multiplicación por un escalar:} \\ $R_{i} \leftarrow \alpha R_{i} + R_{j}$.
    \item \textbf{Operador de intercambio de filas:} \\ $R_{i} \leftrightarrow R_{j}$.
\end{enumerate}

\subsection*{Notas sobre las matrices resultantes}
\label{sec:0_notas_sobre_las_matrices_resultantes}

Sea $A$ una matriz de $m \times n$ y sean $a, b, c, d, e, f$ números reales:

\begin{enumerate}
    \item \textbf{Determinante igual a cero}: $|A| = 0$ \\ El sistema tiene múltiples soluciones. \\ Ejemplo: $\left[ \begin{array}{rr|r} a & b & c \\ 0 & 0 & 0 \end{array} \right]$
    \item \textbf{Determinante igual a cero}: $|A| = 0$ \\ El sistema no tiene soluciones, es decir, es inconsistente. \\ Ejemplo: $\left[ \begin{array}{rr|r} a & b & c \\ 0 & 0 & f \end{array} \right], \quad f \neq 0$.
    \item \textbf{Determinante distinto de cero}: $|A| \neq 0$ \\ El sistema tiene una única solución. \\ Ejemplo: $\left[ \begin{array}{rr|r} a & b & c \\ d & e & f \end{array} \right]$
\end{enumerate}

\subsection*{Inversión de matrices}
\label{sec:0_inversion_de_matrices}

\subsubsection*{Inversión por cofactores}
\label{sec:0_inversion_por_cofactores}

El método de inversión de matrices por cofactores es una técnica para encontrar la inversa de una matriz cuadrada. Este método se basa en el concepto de cofactor de un elemento de una matriz y utiliza la fórmula de la inversa de una matriz dada por:

$$A^{-1} = \frac{1}{\det(A)}\text{adj}(A)$$

donde $\det(A)$ es el determinante de la matriz $A$ y $\text{adj}(A)$ es la matriz adjunta de $A$. La matriz adjunta de $A$ se puede calcular como:

$$\text{adj}(A) = C^T$$

donde $C$ es la matriz de cofactores de $A$. La matriz de cofactores de $A$ se define como:

$$C_{ij} = (-1)^{i+j} M_{ij}$$

donde $M_{ij}$ es el menor de $A$ que se obtiene eliminando la fila $i$ y la columna $j$ de la matriz $A$.

Para calcular la inversa de una matriz $A$ usando este método, primero se calcula el determinante de la matriz $A$ y luego se calcula la matriz de cofactores $C$ de $A$. Luego se calcula la matriz adjunta de $A$ como $C^T$. Finalmente, se utiliza la fórmula de la inversa de la matriz para calcular la inversa de $A$ como:

$$A^{-1} = \frac{1}{\det(A)}C^T$$

Este método funciona siempre y cuando el determinante de la matriz $A$ sea distinto de cero. Si el determinante de la matriz es cero, entonces la matriz no tiene inversa.

\subsubsection*{Inversión por operadores gaussianos}
\label{sec:0_inversion_por_operadores_gaussianos}

Este método se basa en el uso de operadores matriciales especiales llamados operadores gaussianos, que son matrices que tienen la propiedad de "cancelar" una fila o columna de una matriz al multiplicarla por ellos.

Para invertir una matriz $A$ usando este método, se sigue el siguiente proceso:

Sea $A$ una matriz cuadrada. Por ejemplo: \begin{align*}
    A = \left[ \begin{array}{rrr} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{array} \right]
\end{align*}

\begin{enumerate}
    \item Se obtiene la matriz identidad $I$ del mismo tamaño que $A$ mediante la concatenación de las matrices $A$ y $I$: $[A|I]$. Por ejemplo: \\ \begin{align*}
        \left[ \begin{array}{rrr|rrr} a_{11} & a_{12} & a_{13} & 1 & 0 & 0 \\ a_{21} & a_{22} & a_{23} & 0 & 1 & 0 \\ a_{31} & a_{32} & a_{33} & 0 & 0 & 1 \end{array} \right]
    \end{align*}
    \item Se aplican operadores gaussianos a la matriz $[A|I]$ para reducirla a una matriz escalonada reducida. Esto implica eliminar los elementos debajo de la diagonal principal mediante la multiplicación por operadores gaussianos adecuados. Por ejemplo: \\ \begin{align*}
        \left[ \begin{array}{rrr|rrr} b_{11} & b_{12} & b_{13} & c_{11} & c_{12} & c_{13} \\ 0 & b_{22} & b_{23} & c_{21} & c_{22} & c_{23} \\ 0 & 0 & b_{33} & c_{31} & c_{32} & c_{33} \end{array} \right]
    \end{align*}
    \item Una vez que la matriz se ha reducido a una matriz escalonada reducida, se aplican operadores gaussianos adecuados a la matriz para convertirla en la matriz identidad. Los operadores gaussianos se aplican a las filas superiores de la matriz para eliminar los elementos encima de la diagonal principal. Por ejemplo: \\ \begin{align*}
        \left[ \begin{array}{rrr|rrr} 1 & 0 & 0 & d_{11} & d_{12} & d_{13} \\ 0 & 1 & 0 & d_{21} & d_{22} & d_{23} \\ 0 & 0 & 1 & d_{31} & d_{32} & d_{33} \end{array} \right]
    \end{align*}
    \item La inversa de la matriz $A$ se encuentra en la parte derecha de la matriz resultante, es decir, en la sección que correspondía a la matriz identidad original. \\ \begin{align*}
        A^{-1} = \left[ \begin{array}{rrr} d_{11} & d_{12} & d_{13} \\ d_{21} & d_{22} & d_{23} \\ d_{31} & d_{32} & d_{33} \end{array} \right]
    \end{align*}
\end{enumerate}

Este método funciona siempre y cuando la matriz $A$ sea invertible, es decir, tenga un determinante distinto de cero. Si el determinante de la matriz es cero, entonces la matriz no tiene inversa y este método no puede utilizarse.